import os
import string
from collections import Counter

# generator for the datasets
res_path = '../res/files'
def get_dataset():
  files_list = []
  for path, _, files in os.walk(res_path):
    for name in files:
      files_list.append(os.path.join(path, name))
  return files_list


# what to do with the final result
def process_result(result):
  print(result.most_common(5))


# the mapping methods
def map(input):
  # clean the file
  file_contents = read_file(input)
  for char in string.punctuation:
    file_contents = file_contents.replace(char, ' ')
  file_contents = file_contents.lower()

  # get the word counts
  return Counter(file_contents.split())


# The reduce methods
def reduce_start_value():
  return Counter()

def reduce(input, total):
  return input + total


